{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0JKbsPfKhymwazTPv3dpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saharshhhh/NLP/blob/main/Stemming_And_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkM_vyxa3OJ",
        "outputId": "e20f7ddb-d18c-4d78-af6d-6de332ec9574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "7UsYN2XZbHVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "lnj2JSfMbck8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para=\"The use of this dataset may be helpful for natural language processing tasks such as text classification, summarization, or language modeling. Additionally, the dataset could be used for training machine learning algorithms that require large amounts of textual data. However, it is worth noting that the dataset may contain biases or inaccuracies, as the information on Wikipedia is not always verified or peer-reviewed.\""
      ],
      "metadata": {
        "id": "K5n8JFeXboCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=sent_tokenize(para)"
      ],
      "metadata": {
        "id": "bWi7MZdvb670"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "    review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "    review=review.lower()\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "jCQzxzaHcABE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvg0jHnIcbqd",
        "outputId": "edae5e4a-0ddf-4307-945f-25e3224e49a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the use of this dataset may be helpful for natural language processing tasks such as text classification  summarization  or language modeling ',\n",
              " 'additionally  the dataset could be used for training machine learning algorithms that require large amounts of textual data ',\n",
              " 'however  it is worth noting that the dataset may contain biases or inaccuracies  as the information on wikipedia is not always verified or peer reviewed ']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNIeWZiPccYb",
        "outputId": "23bde984-bff1-456e-aa89-0430f8c79179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING WITH PORTER STEMMER"
      ],
      "metadata": {
        "id": "JoM5us75cyIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
      ],
      "metadata": {
        "id": "BJGbzBHEc3ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port=PorterStemmer()\n",
        "lanc=LancasterStemmer()\n",
        "snow=SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "IcE2hdDddBSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snow.stem(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "09oQ6O6IdFzb",
        "outputId": "a2771882-ed44-4ce2-af7c-2621ff052b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the use of this dataset may be helpful for natural language processing tasks such as text classification, summarization, or language modeling. additionally, the dataset could be used for training machine learning algorithms that require large amounts of textual data. however, it is worth noting that the dataset may contain biases or inaccuracies, as the information on wikipedia is not always verified or peer-reviewed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port.stem(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "DGauOl8TdQOt",
        "outputId": "10ec4df0-66da-4c3e-8e83-5a638e090bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the use of this dataset may be helpful for natural language processing tasks such as text classification, summarization, or language modeling. additionally, the dataset could be used for training machine learning algorithms that require large amounts of textual data. however, it is worth noting that the dataset may contain biases or inaccuracies, as the information on wikipedia is not always verified or peer-reviewed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lanc.stem(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "BYak1jh-dSxb",
        "outputId": "ad09126d-a4d6-4573-feb9-8e8dfd01d8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the use of this dataset may be helpful for natural language processing tasks such as text classification, summarization, or language modeling. additionally, the dataset could be used for training machine learning algorithms that require large amounts of textual data. however, it is worth noting that the dataset may contain biases or inaccuracies, as the information on wikipedia is not always verified or peer-reviewed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "!pip install stopwords\n",
        "sentences=sent_tokenize(para)\n",
        "stemmer=PorterStemmer()\n",
        "stopword=stopwords.words(\"english\")\n",
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejmOZE33dUCT",
        "outputId": "2da2f1d6-69bb-4721-cac0-e313d776020f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stopwords in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_stopwords=list(set(stopwords.words(\"english\")))\n",
        "len(original_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arMi6TXVewmz",
        "outputId": "2184c282-ae56-4aa1-9dbf-15274652c049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_stopwords=['sun','moon','planet']\n",
        "new_stopwords=original_stopwords+my_stopwords\n",
        "len(new_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkUeSOkqfq4k",
        "outputId": "afdd26b9-0d23-422e-93c7-33f9dac3f713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION"
      ],
      "metadata": {
        "id": "om9FlxQ7gZ78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=WordNetLemmatizer()\n",
        "import string"
      ],
      "metadata": {
        "id": "9urr0SwSge5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "492Wpg1Mgmvj",
        "outputId": "46da308d-41ec-4fa9-8c17-5f2bed9cb76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "    review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[word for word in review if word not in string.punctuation]\n",
        "    review=[lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
        "    review=\" \".join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "qrx5qsZlf15j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elYBB2pKhZlE",
        "outputId": "be75e6be-ddd7-4fb1-8a0f-cae14e1b6646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['use dataset may helpful natural language processing task text classification summarization language modeling',\n",
              " 'additionally dataset could used training machine learning algorithm require large amount textual data',\n",
              " 'however worth noting dataset may contain bias inaccuracy information wikipedia always verified peer reviewed']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RfkW4oOht0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}